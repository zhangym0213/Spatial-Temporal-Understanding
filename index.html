<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ST-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?</title>
    <!-- å¼•å…¥ Font Awesome å›¾æ ‡åº“ -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <!-- å¼•å…¥ Academicons å›¾æ ‡åº“ -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f8f8f8;
        }
        .robot {
            background-color: #ffffff;
            padding: 40px 0; /* å¢åŠ ä¸Šä¸‹é—´è· */
            text-align: center;
        }
        .robot .title {
            font-size: 3.5em; /* è¿›ä¸€æ­¥å¢å¤§å­—å· */
            font-weight: bold; /* åŠ ç²— */
            margin-bottom: 10px;
        }
        .robot .subtitle {
            font-size: 1.2em;
            color: #666;
        }
        .publication-links {
            margin-top: 20px;
        }
        .publication-links .link-block {
            display: inline-block;
            margin: 0 5px; /* å‡å°å·¦å³é—´è· */
        }
        .publication-links a {
            text-decoration: none;
            color: #ffffff;
            font-weight: bold;
            background-color: #333333;
            padding: 10px 20px; /* å¢åŠ å†…è¾¹è· */
            border-radius: 20px;
            display: flex;
            align-items: center;
            transition: background-color 0.3s; /* æ·»åŠ è¿‡æ¸¡æ•ˆæœ */
        }
        .publication-links a:hover {
            background-color: #555555;
        }
        .publication-links i {
            margin-right: 5px;
        }
        .icon {
            display: inline-block;
            margin-right: 5px;
        }
    
        /* Abstract Section Styles */
        .abstract-section {
            background-color: #ffffff;
            padding: 40px 0;
        }

        .abstract-section h2 {
            font-size: 2.0em;
            margin-bottom: 20px;
            text-align: center;
            font-family: 'Times New Roman', Times, serif; /* è®¾ç½®å­—ä½“ä¸º Times New Roman */
        }

        .abstract-section p {
            font-size: 1.5em;
            color: #333;
            text-align: justify; /* å¯¹é½æ–‡æœ¬ */
            margin: 0 auto;
            max-width: 800px; /* æ§åˆ¶æ®µè½å®½åº¦ */
            font-family: 'Times New Roman', Times, serif; /* è®¾ç½®å­—ä½“ä¸º Times New Roman */
        }

        /* Conclusion Section Styles */
        .conclusion-section {
            background-color: #ffffff;
            padding: 40px 0;
            margin: 0;
            width: 100%; /* è®¾ç½®å®½åº¦ä¸ºæ•´é¡µå®½åº¦ */
        }

        .conclusion-section .container {
            max-width: 100%; /* ç¡®ä¿å®¹å™¨å®½åº¦ä¸ºæ•´é¡µå®½åº¦ */
            padding: 0 20px; /* æ·»åŠ ä¸€äº›å†…è¾¹è·ä»¥é€‚åº”å°å±å¹• */
        }

        .conclusion-section h2 {
            font-size: 2.0em;
            margin-bottom: 20px;
            text-align: center;
            font-family: 'Times New Roman', Times, serif; /* è®¾ç½®å­—ä½“ä¸º Times New Roman */
        }

        .conclusion-section p {
            font-size: 1.5em;
            color: #333;
            text-align: justify; /* å¯¹é½æ–‡æœ¬ */
            margin: 0 auto;
            max-width: 800px; /* æ§åˆ¶æ®µè½å®½åº¦ */
            font-family: 'Times New Roman', Times, serif; /* è®¾ç½®å­—ä½“ä¸º Times New Roman */
        }
        .demo-video-section {
            background-color: #ffffff; /* è®¾ç½®èƒŒæ™¯é¢œè‰²ä¸ºç™½è‰² */
            padding: 40px 100px; /* å¢åŠ ä¸Šä¸‹å’Œå·¦å³é—´è· */
        }
        .demo-video-section h2 {
            font-size: 2.0em; /* å¢å¤§å­—ä½“å¤§å° */
            margin-bottom: 10px;
            font-family: 'Times New Roman', Times, serif; /* è®¾ç½®å­—ä½“ä¸º Times New Roman */
        }
        .demo-video-section p {
            font-size: 1.5em;
            color: #333;
            margin-bottom: 20px;
            font-family: 'Times New Roman', Times, serif; /* è®¾ç½®å­—ä½“ä¸º Times New Roman */
        }
        .video-container {
            display: flex;
            justify-content: center;
            gap: 10px; /* è§†é¢‘ä¹‹é—´çš„é—´è· */
            margin-bottom: 20px; /* æ¯è¡Œä¹‹é—´çš„é—´è· */
        }
        .video-container video {
            border-radius: 8px; /* è§†é¢‘è¾¹è§’åœ†æ»‘ */
            width: 400px; /* è§†é¢‘å®½åº¦ */
            height: auto; /* è§†é¢‘é«˜åº¦ï¼Œä¿æŒ16:9æ¯”ä¾‹ */
        }
        .title .highlight {
            color: orange; /* æ”¹ä¸ºæ©™è‰² */
        }
        /* General Section Styles */
        .logo-section,
        .comparison-section,
        .pipeline-section,
        .results-section {
            background-color: #ffffff;
            padding: 40px 0; /* Adjust padding to control vertical spacing */
            margin: 0; /* Remove margin to ensure no space between sections */
        }

        .container {
            max-width: 1200px; /* Adjust max-width as needed */
            margin: 0 auto; /* Center the container */
            padding: 0 20px; /* Add some padding for smaller screens */
        }

        /* Section Titles and Descriptions */
        h2 {
            font-size: 2.0em;
            margin-bottom: 20px; /* Add some space below the title */
            text-align: center; /* Center-align titles */
            font-family: 'Times New Roman', Times, serif; /* è®¾ç½®å­—ä½“ä¸º Times New Roman */
        }

        p {
            font-size: 1.5em;
            color: #333;
            margin-bottom: 20px;
            text-align: left; /* Align text to the left */
            font-family: 'Times New Roman', Times, serif; /* è®¾ç½®å­—ä½“ä¸º Times New Roman */
        }

        /* Image Containers */
        .image-container {
            width: 100%; /* Ensure image container takes full width */
            text-align: center; /* Center-align images */
        }

        /* Full-width images */
        .full-width-image {
            width: 100%; /* Make images full-width */
            max-width: 100%; /* Ensure images do not overflow */
            height: auto;
            border: 1px solid #ddd;
            border-radius: 8px;
        }

        .quiz-section {
            background-color: #ffffff; /* è®¾ç½®èƒŒæ™¯é¢œè‰²ä¸ºç™½è‰² */
            padding: 40px 100px; /* å¢åŠ ä¸Šä¸‹å’Œå·¦å³é—´è· */
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            gap: 20px; /* è°ƒæ•´å·¦å³é—´è· */
        }
        .quiz-section-title {
            margin-bottom: 20px; /* æ·»åŠ ä¸€äº›é—´è· */
            text-align: center; /* æ ‡é¢˜å±…ä¸­å¯¹é½ */
        }
        .quiz-content {
            display: flex;
            gap: 20px;
        }
        .quiz-section .video-column {
            flex: 3;
            max-width: 60%;
        }
        .quiz-section .text-column {
            flex: 2;
            max-width: 40%;
            padding-right: 20px; /* æ·»åŠ å³è¾¹è·é˜²æ­¢æº¢å‡º */
            box-sizing: border-box; /* ç¡®ä¿paddingåŒ…å«åœ¨å®½åº¦å†… */
        }
        .quiz-section h2 {
            font-size: 2.0em; /* å¢å¤§å­—ä½“å¤§å° */
            margin-bottom: 10px;
            font-family: 'Times New Roman', Times, serif; /* è®¾ç½®å­—ä½“ä¸º Times New Roman */
        }
        .quiz-section p {
            font-size: 1em;
            color: #333;
            margin-bottom: 20px;
        }
        .quiz-section video {
            border-radius: 8px; /* è®¾ç½®è§†é¢‘çš„åœ†è§’ä¸º8px */
            width: 100%; /* è§†é¢‘å®½åº¦å æ»¡æ•´ä¸ªå·¦è¾¹æ  */
            height: auto; /* è§†é¢‘é«˜åº¦è‡ªåŠ¨è°ƒæ•´ */
        }
        .tabs {
        display: flex;
        border-bottom: 2px solid #ddd;
        padding: 0;
        margin-top: 10px;
        }
        .tab-button {
            flex: 1;
            padding: 12px 20px;
            text-align: center;
            background-color: transparent;
            border: none;
            cursor: pointer;
            transition: color 0.3s;
            font-size: 1.1em;
            font-weight: bold;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
            color: #555;
            position: relative;
        }
        .tab-button i {
            font-size: 1.2em;
        }
        .tab-button.active {
            color: #FFA500;
        }
        .tab-button.active::after {
            content: "";
            position: absolute;
            bottom: -2px;
            left: 0;
            width: 100%;
            height: 4px;
            background-color: #FFA500;
        }
        /* è®¾ç½®é—®é¢˜å­—ä½“ä¸ºåœ†ä½“ï¼Œå¹¶è°ƒæ•´å¤§å° */
        /* å±…ä¸­é—®é¢˜å’Œé€‰é¡¹ */
        .quiz-question p {
            font-family: 'Times New Roman', Times, serif; /* ä¿®æ”¹å­—ä½“ä¸º Times New Roman */
            font-size: 28px; /* åŠ å¤§å­—ä½“ */
            font-weight: bold; /* åŠ ç²— */
            text-align: center;
            margin-bottom: 20px;
        }

        .quiz-options {
            list-style-type: none;
            padding: 0;
            display: flex;
            flex-direction: column;
            align-items: center; /* å³å¯¹é½ */
        }

        .quiz-options li {
            margin: 10px 0;
            display: flex;
            max-width: 300px; /* æ§åˆ¶æœ€å¤§å®½åº¦ */
        }

        /* é€‰é¡¹æŒ‰é’®æ ·å¼ */
        .quiz-options button {
            display: flex;
            align-items: center;
            width: auto; /* è‡ªé€‚åº”å®½åº¦ */
            padding: 15px;
            background-color: #f0f0f0;
            border: 1px solid #ccc;
            border-radius: 5px;
            cursor: pointer;
            font-size: 20px; /* é€‰é¡¹å­—ä½“å¤§å° */
            text-align: left;
        }

        .quiz-options button:hover {
            background-color: #ddd;
        }

        /* é€‰é¡¹å­—æ¯æ ‡ç­¾æ ·å¼ */
        .option-label {
            font-weight: bold;
            color: #333;
            margin-right: 10px;
            width: auto; /* è‡ªé€‚åº”å®½åº¦ */
            white-space: nowrap; /* é˜²æ­¢æ¢è¡Œ */
        }

        /* åé¦ˆä¿¡æ¯æ ·å¼ */
        .quiz-feedback {
            margin-top: 20px;
            font-size: 20px;
            font-weight: bold;
            text-align: center;
        }
        
        /* æ–°å¢æ ·å¼è§„åˆ™ï¼Œé’ˆå¯¹ route å’Œ direction é—®é¢˜ */
        .quiz-feedback.hide-groundtruth span:nth-child(2) {
            display: none;
        }

        /* èƒŒæ™¯è‰²å’Œå­—ä½“ç»Ÿä¸€ */
        .tabs-section {
            background-color: #ffffff; /* è®¾ç½®ä¸é¡µé¢å…¶ä»–éƒ¨åˆ†ä¸€è‡´çš„èƒŒæ™¯è‰² */
            padding: 40px 0;
        }

        .tabs-section .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        .tabs-section h2{
            font-size: 2.0em;
            text-align: center;
            font-family: 'Times New Roman', Times, serif;
        }

        .tabs-section p{
            font-size: 1.5em;
            color: #333;
            font-family: 'Times New Roman', Times, serif;
        }

        /* Task Definition Tabs */
        .task-tabs {
            display: flex;
            border-bottom: 2px solid #ddd;
            margin-top: 10px;
        }
        .task-tab-button {
            flex: 1;
            padding: 12px 20px;
            text-align: center;
            cursor: pointer;
            font-size: 1.1em;
            font-weight: bold;
            color: #555;
            border: none;
            background: none;
        }
        .task-tab-button.active {
            color: #FFA500;
            border-bottom: 4px solid #FFA500;
        }
        .task-tab-content {
            display: none;
            padding: 20px;
        }
        .task-tab-content.active {
            display: block;
        }

        /* More Examples Section Styles */
        .more-examples-section {
            background-color: #ffffff; /* ç¡®ä¿èƒŒæ™¯ä¸ºç™½è‰² */
            padding: 40px 0;
        }

        .image-slider {
            position: relative;
            max-width: 1200px;
            margin: 0 auto;
            overflow: visible;
            height: 600px;
        }

        /* ä¿®æ”¹slides-containeræ ·å¼ */
        .slides-container {
            position: relative;
            width: 100%;
            height: 100%;
            overflow: visible; /* ç¡®ä¿å®¹å™¨å…è®¸å†…å®¹æº¢å‡º */
        }

        /* ä¿®æ”¹slideæ ·å¼ */
        .slide {
            position: absolute;
            width: 100%;
            opacity: 0;
            transition: opacity 1s ease-in-out;
            top: 0;
            left: 0;
            z-index: 1; /* è®¾ç½®åŸºç¡€z-index */
        }

        .slide.active {
            opacity: 1;
            z-index: 2; /* æ´»åŠ¨å¹»ç¯ç‰‡ç¨é«˜ */
        }

        /* ä¿®æ”¹å›¾ç‰‡æ‚¬åœæ•ˆæœ */
        .full-width-image {
            width: 100%;
            max-width: 100%;
            border-radius: 8px;
            transition: transform 0.3s ease-in-out;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            transform-origin: center center; /* ç¡®ä¿ä»ä¸­å¿ƒæ”¾å¤§ */
            position: relative; /* æ·»åŠ ç›¸å¯¹å®šä½ */
        }

        .full-width-image:hover {
            transform: scale(1.1);
            z-index: 20; /* è®¾ç½®è¶³å¤Ÿé«˜çš„z-indexç¡®ä¿åœ¨æœ€å‰ */
            position: relative; /* ç¡®ä¿z-indexç”Ÿæ•ˆ */
        }

        .slider-controls {
            position: absolute;
            bottom: -70px;  /* ä»åŸæ¥çš„-50pxè°ƒæ•´ä¸º-70pxï¼Œä½¿æŒ‰é’®æ›´é ä¸‹ */
            left: 0;
            right: 0;
            display: flex;
            justify-content: center;
            gap: 20px;
            z-index: 5;
            margin-top: 30px; /* é¢å¤–å¢åŠ ä¸Šè¾¹è· */
        }

        .prev-button, .next-button {
            background-color: #333333;
            color: white;
            border: none;
            padding: 12px 24px;
            cursor: pointer;
            font-size: 1.2em;
            border-radius: 30px;
            transition: background-color 0.3s;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            min-width: 120px;
        }

        .prev-button:hover, .next-button:hover {
            background-color: #555555;
        }

        .prev-button i, .next-button i {
            margin: 0 8px;
        }


        /* æ–°å¢å›¾ç‰‡æ”¾å¤§æ ·å¼ */
        .image-container img {
            cursor: pointer;
            transition: transform 0.3s ease-in-out;
        }

        .image-container img:hover {
            transform: scale(1.2);
        }
    </style>
</head>
<body>
    <section class="robot">
        <div class="container">
          <h1 class="title">
            <span class="highlight">ST-Bench</span> : Are MLLMs Ready for <br> Precise Spatial-Temporal World Understanding?
          </h1>
            <div class="publication-links">
                <span class="link-block">
                    <a href="https://arxiv.org/abs/your-arxiv-id" target="_blank">
                        <span class="icon"><i class="ai ai-arxiv"></i></span> arXiv
                    </a>
                </span>
                <span class="link-block">
                    <a href="assets/your-paper-name.pdf" target="_blank">
                        <span class="icon"><i class="fas fa-file-pdf"></i></span> PDF
                    </a>
                </span>
                <span class="link-block">
                    <a href="https://github.com/your-repo-name/your-dataset-folder" target="_blank">
                        <span class="icon"><i class="fas fa-database"></i></span> Dataset
                    </a>
                </span>
                <span class="link-block">
                <a href="https://github.com/IranQin/MP5" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
            </div>
        </div>
    </section>

    <!-- Logo Section -->
    <section class="logo-section">
        <div class="container">
            <div class="image-container">
                <img src="assets/images/cover.jpg"  alt="Cover" class="full-width-image">
            </div>
        </div>
    </section>

    <!-- Abstract Section -->
    <section class="abstract-section">
        <div class="container">
            <h2>Abstract</h2>
            <p>
                The use of Multimodal Large Language Models (MLLMs) as an end-to-end solution for Embodied AI and Autonomous Driving has become a prevailing trend. While MLLMs have been extensively studied for visual semantic understanding tasks, their ability to perform precise and quantitative spatial-temporal understanding in real-world applications remains largely unexamined, leading to uncertain prospects. To evaluate models' Spatial-Temporal Intelligence, we introduce ST-Bench, a benchmark designed to evaluate MLLMs' spatial-temporal understanding through challenging tasks such as estimating and predicting the appearance, pose, displacement, and motion of objects. Our benchmark encompasses a wide range of robot and vehicle operations across desktop, indoor, and outdoor scenarios. 
                The extensive experiments reveals that the state-of-the-art MLLMs still struggle in real-world spatial-temporal understanding, especially in tasks requiring precise distance estimation and motion analysis. 
            </p>
        </div>
    </section>

    <section class="demo-video-section">
        <div class="container">
            <h2>Demo Videos</h2>
            <!-- ç¬¬ä¸€è¡Œè§†é¢‘ -->
            <div class="video-container" style="justify-content: space-between;">
                <video controls autoplay muted loop style>
                    <source src="assets/videos/00001.mp4" type="video/mp4">
                </video>
                <video controls autoplay muted loop style>
                    <source src="assets/videos/00010.mp4" type="video/mp4">
                </video>
                <video controls autoplay muted loop style>
                    <source src="assets/videos/00020.mp4" type="video/mp4">
                </video>
            </div>
            <!-- ç¬¬äºŒè¡Œè§†é¢‘ -->
            <div class="video-container" style="justify-content: space-between;">
                <video controls autoplay muted loop style>
                    <source src="assets/videos/1020365635352417945_7625_000_7645_000_camera_1.mp4" type="video/mp4">
                </video>
                <video controls autoplay muted loop style>
                    <source src="assets/videos/1024360143612057520_3580_000_3600_000_camera_1.mp4" type="video/mp4">
                </video>
                <video controls autoplay muted loop style>
                    <source src="assets/videos/10247954040621004675_2180_000_2200_000_camera_1.mp4" type="video/mp4">
                </video>
            </div>
            <!-- ç¬¬ä¸‰è¡Œè§†é¢‘ -->
            <div class="video-container" style="justify-content: space-between;">
                <video controls autoplay muted loop style>
                    <source src="assets/videos/scene0001_00.mp4" type="video/mp4">
                </video>
                <video controls autoplay muted loop style>
                    <source src="assets/videos/scene0010_00.mp4" type="video/mp4">
                </video>
                <video controls autoplay muted loop style>
                    <source src="assets/videos/scene0020_00.mp4" type="video/mp4">
                </video>
            </div>
        </div>
    </section>

    <!-- Tabs Section -->
    <section class="tabs-section">
        <div class="container">
            <h2>Tasks Definition</h2>
            <p>We have divided the questions into Static Understanding and Dynamic Understanding, and further give definitions to 8 different tasks.</p>
            <div class="task-tabs">
                <button class="task-tab-button active" onclick="openTaskTab(event, 'Static')">Static Understanding</button>
                <button class="task-tab-button" onclick="openTaskTab(event, 'Dynamic')">Dynamic Understanding</button>
            </div>

            <div id="Static" class="task-tab-content">
                <p><strong>Dimensional Measurement.</strong> Concerns estimates of an object's geometric size, such as length, width, and height, as well as the distance between objects or between the camera and an object.<br>
                    <strong>Example:</strong> <em>â€œWhat is the height of this box?â€ or â€œHow close is the camera to the table?â€</em>
                </p>
                <p><strong>Spatial Relation.</strong> Focuses on identifying spatial relationships among objects or between the camera and an object, including front and back, left and right, up and below.<br>
                    <strong>Example:</strong> <em>â€œIs the chair on the left or right side of the table?â€ or â€œWhat is the position of the red bag relative to the fur sofa?â€</em>
                </p>
                <p><strong>3D Video Grounding.</strong> Given a semantic description such as â€œthe red backpack on the brown sofa,â€ the goal is to retrieve the object's 3D bounding box in the camera coordinate system at a specific point in the video.<br>
                    <strong>Example:</strong> <em>â€œLocate the 3D bounding box of the red suitcase near the bed.â€</em>
                </p>
            </div>

            <div id="Dynamic" class="task-tab-content" style="display: none;">
                <p><strong>Displacement and Path Length.</strong> Focuses on how far an object or the camera travels between two given time points.<br>
                    <strong>Example:</strong> <em>â€œHow far has the car traveled from 1s to 18s?â€</em>
                </p>
                <p><strong>Speed and Acceleration.</strong> Investigates motion parameters by integrating spatial displacement with time intervals.<br>
                    <strong>Example:</strong> <em>â€œWhat is the average speed of the camera?â€ or â€œHow quickly is the ball accelerating?â€</em>
                </p>
                <p><strong>Ego-Centric Orientation.</strong> Examines how the cameraâ€™s azimuth orientation, parallel to the ground plane, changes over the duration of the video.<br>
                    <strong>Example:</strong> <em>â€œHow many degrees does the cameraâ€™s horizontal orientation shift from the start of the video to its end?â€</em>
                </p>
                <p><strong>Trajectory Description.</strong> Describes or infers the cameraâ€™s or an objectâ€™s motion path throughout the entire video, potentially involving multiple segments of travel and turns.<br>
                    <strong>Example:</strong> <em>â€œSummarize the camera trajectory, including distances moved and turns made.â€</em>
                </p>
                <p><strong>Pose Estimation.</strong> Given the cameraâ€™s initial 3D pose, including position and orientation, estimates its pose at a specified point in the video using only the observed RGB data.<br>
                    <strong>Example:</strong> <em>â€œGiven the initial pose of the camera, what is the cameraâ€™s pose at the requested time?â€</em>
                </p>
            </div>
        </div>
    </section>

    <!-- Comparison Section -->
    <section class="comparison-section">
        <div class="container">
            <h2>Comparison</h2>
            <div class="image-container">
                <img src="assets/images/comparison.jpg" alt="Comparison" class="full-width-image">
            </div>
            <p>
                <strong>Comparison of ST-Bench with existing benchmarks.</strong> 
                <strong>Data</strong> represents the source of our QA data, where <strong>V</strong> stands for Video and <strong>I</strong> stands for Image. 
                <strong>Env.</strong> indicates the environment in which the data is generated, where <strong>S</strong> represents Simulation and <strong>R</strong> represents Real. 
                The two columns under <strong>View</strong> indicate whether the dataset includes Ego-centric and Allocentric perspectives. 
                The two columns under <strong>Evaluation</strong> specify whether the ground truth is presented in numerical or textual form. 
                The four columns under <strong>Spatio-Temporal</strong> indicate whether the benchmark evaluates spatial distance, direction (with angular precision), velocity, or a precise and comprehensive trajectory description.
            </p>
        </div>
    </section>

    <!-- Pipeline Section -->
    <section class="pipeline-section">
        <div class="container">
            <h2>Pipeline</h2>
            <div class="image-container">
                <img src="assets/images/pipeline.jpg" alt="Pipeline" class="full-width-image">
            </div>
            <p><strong>I. Data Collection</strong> Collected data from Desktop, Indoor, and Outdoor scenarios using Omni6DPose for 6D object pose estimation, ScanNet for indoor 3D scene reconstruction, and Waymo for autonomous driving. These datasets provide frame-by-frame camera parameters and point clouds.</p>
            <p><strong>II. Automatic QA Pair Generation</strong> Generated QA pairs with MLLMs using detailed object descriptions and computed ground-truth information for each task. This process produced a diverse set of questions and challenging answer options.</p>
            <p><strong>III. Human Quality Control</strong> Conducted human quality control to filter and refine QA pairs, addressing issues like inaccurate descriptions and insufficient video information. This ensured high-quality questions and shuffled answer options for robust evaluation.</p>
            <p><strong>IV. Fine-Grained Adjustment</strong> Adjusted QA pairs with scaling factors to match the precision needs of different scenarios, from millimeters for desktop settings to meters for outdoor environments. This fine-grained adjustment helps train and evaluate MLLMs effectively.</p>
        </div>
    </section>

    <section class="results-section">
        <div class="container">
            <h2>Results</h2>
            <div style="display: flex; gap: 20px;">
                <div style="flex: 1; display: flex; flex-direction: column; gap: 20px;">
                    <div>
                        <img src="assets/images/results.jpg" alt="Results" class="full-width-image">
                    </div>
                    <div>
                        <p><strong>Main Results.</strong> The experimental results in indoor, outdoor, and desktop environments consistently demonstrate that MLLMs exhibit significant limitations in Dimensional Measurement and displacement & estimation tasks. Across all evaluated scenarios, these models achieve substantially lower performance compared to other spatial reasoning tasks, such as pose estimation, directional reasoning, and 3D video grounding. In particular, performance is uniformly low among all models tested, indicating a generalized deficiency in accurately perceiving and estimating distances and displacements, rather than shortcomings of specific model architectures.</p>
                    </div>
                </div>
                <div style="flex: 1;">
                    <img src="assets/images/radar.jpg" alt="Radar" class="full-width-image">
                </div>
            </div>
        </div>
    </section>

    <!-- å¦‚æœæœ‰æ›´å¤šçš„ç»“æœæµ‹å‡ºæ¥ï¼Œé‚£ä¹ˆæ–‡å­—æ”¾æœ€åº•ä¸‹ -->
    <!-- <section class="results-section">
        <div class="container">
            <h2>Results</h2>
            <div class="image-container" style="display: flex; justify-content: space-between; gap: 20px;">
                <div style="flex: 1;">
                    <img src="assets/images/results.jpg" alt="Results" class="full-width-image">
                </div>
                <div style="flex: 1;">
                    <img src="assets/images/radar.jpg" alt="Radar" class="full-width-image">
                </div>
            </div>
            <p><strong>Main Results.</strong> The experimental results in indoor, outdoor, and desktop environments consistently demonstrate that MLLMs exhibit significant limitations in Dimensional Measurement and displacement & estimation tasks. Across all evaluated scenarios, these models achieve substantially lower performance compared to other spatial reasoning tasks, such as pose estimation, directional reasoning, and 3D video grounding. In particular, performance is uniformly low among all models tested, indicating a generalized deficiency in accurately perceiving and estimating distances and displacements, rather than shortcomings of specific model architectures. </p>
        </div>
    </section> -->

    <section class="quiz-section">
        <div class="container">
            <h2 class="quiz-section-title">QUIZ</h2>
            <div class="quiz-content" style="display: flex; gap: 20px;">
                <div class="video-column" style="flex: 3;">
                    <video id="quiz-video" controls autoplay muted loop style="width: 100%; border-radius: 8px;">
                        <source src="assets/videos/1024360143612057520_3580_000_3600_000_camera_1.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="text-column" style="flex: 2;">
                    <div class="tabs">
                        <button class="tab-button active" onclick="showTab(0)"><i class="fas fa-rocket"></i> Speed & Acceleration </button>
                        <button class="tab-button" onclick="showTab(1)"><i class="fa-solid fa-route"></i> Trajectory Description</button>
                        <button class="tab-button" onclick="showTab(2)"><i class="fas fa-ruler"></i> Dimensional Measurement </button>
                    </div>
                    <div class="tab-content" id="tab-content">
                        <div class="quiz-question">
                            <p>What is the velocity of the object?</p>
                            <ul class="quiz-options">
                                <li><button onclick="checkAnswer(0, 0)">10 m/s</button></li>
                                <li><button onclick="checkAnswer(0, 1)">20 m/s</button></li>
                                <li><button onclick="checkAnswer(0, 2)">30 m/s</button></li>
                            </ul>
                            <p id="quiz-feedback-0" class="quiz-feedback"></p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="more-examples-section">
        <div class="container">
            <h2>More Examples</h2>
            <div class="image-slider">
                <div class="slides-container">
                    <div class="slide active" id="slide-0">
                        <img src="assets/images/3radar.jpg" alt="Example 1" class="full-width-image">
                    </div>
                    <div class="slide" id="slide-1">
                        <img src="assets/images/pipeline.jpg" alt="Example 2" class="full-width-image">
                    </div>
                    <div class="slide" id="slide-2">
                        <img src="assets/images/cover.jpg" alt="Example 3" class="full-width-image">
                    </div>
                </div>
                <div class="slider-controls">
                    <button class="prev-button" onclick="prevSlide()">
                        <i class="fas fa-chevron-left"></i> Prev
                    </button>
                    <button class="next-button" onclick="nextSlide()">
                        Next <i class="fas fa-chevron-right"></i>
                    </button>
                </div>
            </div>
        </div>
    </section>

    <script>
        let currentSlide = 0;
        const slides = document.querySelectorAll('.slide');
        const totalSlides = slides.length;

        // åˆå§‹åŒ–æ˜¾ç¤ºç¬¬ä¸€å¼ 
        slides[0].classList.add('active');
        slides[0].style.opacity = 1;

        function showSlide(index) {
            // å…ˆé‡ç½®æ‰€æœ‰å¹»ç¯ç‰‡çŠ¶æ€
            slides.forEach(slide => {
                slide.style.zIndex = 1;
                slide.classList.remove('active');
                slide.style.opacity = 0;
            });
            
            // è®¾ç½®æ–°æ´»åŠ¨å¹»ç¯ç‰‡
            slides[index].classList.add('active');
            slides[index].style.zIndex = 2;
            setTimeout(() => {
                slides[index].style.opacity = 1;
            }, 50);
            
            currentSlide = index;
        }

        function nextSlide() {
            let nextSlide = (currentSlide + 1) % totalSlides;
            showSlide(nextSlide);
        }

        function prevSlide() {
            let prevSlide = (currentSlide - 1 + totalSlides) % totalSlides;
            showSlide(prevSlide);
        }

        // è‡ªåŠ¨åˆ‡æ¢
        let autoSlideInterval;
        function startAutoSlide() {
            autoSlideInterval = setInterval(nextSlide, 3000);
        }

        function stopAutoSlide() {
            clearInterval(autoSlideInterval);
        }

        // åˆå§‹åŒ–
        startAutoSlide();

        // é¼ æ ‡æ‚¬åœæ§åˆ¶
        const slider = document.querySelector('.image-slider');
        slider.addEventListener('mouseover', stopAutoSlide);
        slider.addEventListener('mouseout', startAutoSlide);
    </script>

    <section class="conclusion-section">
        <div class="container">
            <h2>Conclusion</h2>
            <p>
                We introduced ST-Bench, a comprehensive benchmark to assess MLLMsâ€™ spatial-temporal understanding through over 300 real-world videos and 2,000 QA pairs of robot desktop, indoor, and outdoor scenarios. Experiments show that, while state-of-the-art MLLMs handle basic pose estimation and object grounding competently, they often struggle with more fine-grained tasks such as precise distance and velocity estimation, displacement tracking, and ego-centric orientation. These shortcomings appear to stem from issues like sparse temporal sampling in pretraining, insufficient 3D annotations, and a lack of dedicated physical reasoning modules. By highlighting these gaps, ST-Bench provides a valuable platform for guiding future research on strengthening spatial-temporal understanding in MLLMs â€” an essential step toward improving their applicability in complex real-world applications.
            </p>
        </div>
    </section>

    <script>
        function openTaskTab(evt, tabName) {
            var i, tabcontent, tablinks;
            tabcontent = document.getElementsByClassName("task-tab-content");
            for (i = 0; i < tabcontent.length; i++) {
                tabcontent[i].style.display = "none";
            }
            tablinks = document.getElementsByClassName("task-tab-button");
            for (i = 0; i < tablinks.length; i++) {
                tablinks[i].className = tablinks[i].className.replace(" active", "");
            }
            document.getElementById(tabName).style.display = "block";
            evt.currentTarget.className += " active";
        }
    </script>

  <script>
    // å®šä¹‰é—®é¢˜å’Œç­”æ¡ˆ
    // æ›´æ–°é—®é¢˜å’Œç­”æ¡ˆæ•°ç»„ï¼Œç§»é™¤ç¬¬å››ä¸ªé—®é¢˜
    const questions = [
        {
            question: "What is the velocity of the object when t=0s ?",
            options: ["10 m/s", "20 m/s", "30 m/s", "40 m/s"],
            correctAnswer: 1,
            GroundTruth: "The GroundTruth is 19.2m/s."
        },
        {
            question: "What is the distance traveled from t=0s to t=1s?",
            options: ["50 m", "100 m", "150 m", "200 m"],
            correctAnswer: 2,
            GroundTruth: "The GroundTruth is 152m."
        },
        {
            question: "What is the route taken?",
            options: ["Route A", "Route B", "Route C","Route D"],
            correctAnswer: 0,
            GroundTruth: "The correct answer is Route A.",
            isRouteOrDirection: true
        }
    ];

    // æ›´æ–°æ—¶é—´ç‚¹æ•°ç»„ï¼Œç°åœ¨åªæœ‰3ä¸ªæ—¶é—´ç‚¹
    const t1 = 0;
    const t2 = 5;
    const t3 = 10;

    // æ˜¾ç¤º Tab å†…å®¹
    function showTab(index) {
        const question = questions[index];
        const optionsHTML = question.options.map((option, i) => `
            <li>
                <button onclick="checkAnswer(${index}, ${i})">
                    <span class="option-label">${String.fromCharCode(65 + i)}</span>
                    <span class="option-text">${option}</span>
                </button>
            </li>
        `).join("");

        document.getElementById("tab-content").innerHTML = `
            <div class="quiz-question">
                <p>${question.question}</p>
                <ul class="quiz-options">${optionsHTML}</ul>
                <p id="quiz-feedback-${index}" class="quiz-feedback"></p>
            </div>
        `;

        // æ›´æ–° Tab æŒ‰é’®çš„æ¿€æ´»çŠ¶æ€
        document.querySelectorAll(".tab-button").forEach((btn, i) => {
            btn.classList.toggle("active", i === index);
        });
    }

    // æ£€æŸ¥ç­”æ¡ˆ
    function checkAnswer(questionIndex, selectedIndex) {
        const question = questions[questionIndex];
        const feedbackElement = document.getElementById(`quiz-feedback-${questionIndex}`);

        let feedbackContent = "";
        if (selectedIndex === question.correctAnswer) {
            feedbackContent = "<span style='color: green;'> Correct! ğŸ‰</span>";
            // å¦‚æœæ˜¯ route æˆ– direction çš„é—®é¢˜ï¼Œéšè— GroundTruth
            if (question.isRouteOrDirection) {
                feedbackElement.classList.add("hide-groundtruth");
            } else {
                feedbackElement.classList.remove("hide-groundtruth");
                feedbackContent += `<br><span>${question.GroundTruth}</span>`;
            }
        } else {
            feedbackElement.classList.remove("hide-groundtruth");
            feedbackContent = `
                <span style='color: red;'> Incorrect!</span><br>
                <span>${question.GroundTruth}</span>
            `;
        }

        feedbackElement.innerHTML = feedbackContent;
    }


    // è·å–è§†é¢‘å…ƒç´ 
    const video = document.getElementById("quiz-video");

    // è·å–æ‰€æœ‰ Tab æŒ‰é’®
    const tabButtons = document.querySelectorAll(".tab-button");

    // ä¸ºæ¯ä¸ª Tab æŒ‰é’®æ·»åŠ ç‚¹å‡»äº‹ä»¶ç›‘å¬å™¨
    tabButtons.forEach((button, index) => {
        button.addEventListener("click", () => {
            switch (index) {
                case 0:
                    video.currentTime = t1;
                    break;
                case 1:
                    video.currentTime = t2;
                    break;
                case 2:
                    video.currentTime = t3;
                    break;
            }
            showTab(index);
        });
    });

    // åˆå§‹åŒ–æ˜¾ç¤ºç¬¬ä¸€ä¸ª Tab çš„å†…å®¹
    showTab(0);
</script>
  
</body>
</html>