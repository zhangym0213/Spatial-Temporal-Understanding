<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ST-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?</title>
    <!-- 引入 Font Awesome 图标库 -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <!-- 引入 Academicons 图标库 -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f8f8f8;
        }
        .robot {
            background-color: #ffffff;
            padding: 40px 0; /* 增加上下间距 */
            text-align: center;
        }
        .robot .title {
            font-size: 3.5em; /* 进一步增大字号 */
            font-weight: bold; /* 加粗 */
            margin-bottom: 10px;
        }
        .robot .subtitle {
            font-size: 1.2em;
            color: #666;
        }
        .publication-links {
            margin-top: 20px;
        }
        .publication-links .link-block {
            display: inline-block;
            margin: 0 5px; /* 减小左右间距 */
        }
        .publication-links a {
            text-decoration: none;
            color: #ffffff;
            font-weight: bold;
            background-color: #333333;
            padding: 10px 20px; /* 增加内边距 */
            border-radius: 20px;
            display: flex;
            align-items: center;
            transition: background-color 0.3s; /* 添加过渡效果 */
        }
        .publication-links a:hover {
            background-color: #555555;
        }
        .publication-links i {
            margin-right: 5px;
        }
        .icon {
            display: inline-block;
            margin-right: 5px;
        }
    
        /* Abstract Section Styles */
        .abstract-section {
            background-color: #ffffff;
            padding: 40px 0;
        }

        .abstract-section h2 {
            font-size: 2.0em;
            margin-bottom: 20px;
            text-align: center;
            font-family: 'Times New Roman', Times, serif; /* 设置字体为 Times New Roman */
        }

        .abstract-section p {
            font-size: 1.5em;
            color: #333;
            text-align: justify; /* 对齐文本 */
            margin: 0 auto;
            max-width: 800px; /* 控制段落宽度 */
            font-family: 'Times New Roman', Times, serif; /* 设置字体为 Times New Roman */
        }

        /* Conclusion Section Styles */
        .conclusion-section {
            background-color: #ffffff;
            padding: 40px 0;
            margin: 0;
            width: 100%; /* 设置宽度为整页宽度 */
        }

        .conclusion-section .container {
            max-width: 100%; /* 确保容器宽度为整页宽度 */
            padding: 0 20px; /* 添加一些内边距以适应小屏幕 */
        }

        .conclusion-section h2 {
            font-size: 2.0em;
            margin-bottom: 20px;
            text-align: center;
            font-family: 'Times New Roman', Times, serif; /* 设置字体为 Times New Roman */
        }

        .conclusion-section p {
            font-size: 1.5em;
            color: #333;
            text-align: justify; /* 对齐文本 */
            margin: 0 auto;
            max-width: 800px; /* 控制段落宽度 */
            font-family: 'Times New Roman', Times, serif; /* 设置字体为 Times New Roman */
        }
        .demo-video-section {
            background-color: #ffffff; /* 设置背景颜色为白色 */
            padding: 40px 100px; /* 增加上下和左右间距 */
        }
        .demo-video-section h2 {
            font-size: 2.0em; /* 增大字体大小 */
            margin-bottom: 10px;
            font-family: 'Times New Roman', Times, serif; /* 设置字体为 Times New Roman */
        }
        .demo-video-section p {
            font-size: 1.5em;
            color: #333;
            margin-bottom: 20px;
            font-family: 'Times New Roman', Times, serif; /* 设置字体为 Times New Roman */
        }
        .video-container {
            display: flex;
            justify-content: center;
            gap: 10px; /* 视频之间的间距 */
        }
        .video-container video {
            border-radius: 8px; /* 视频边角圆滑 */
            width: 400px; /* 视频宽度 */
            height: auto; /* 视频高度，保持16:9比例 */
        }
        .title .highlight {
            color: orange; /* 改为橙色 */
        }
        /* General Section Styles */
        .logo-section,
        .comparison-section,
        .pipeline-section,
        .results-section {
            background-color: #ffffff;
            padding: 40px 0; /* Adjust padding to control vertical spacing */
            margin: 0; /* Remove margin to ensure no space between sections */
        }

        .container {
            max-width: 1200px; /* Adjust max-width as needed */
            margin: 0 auto; /* Center the container */
            padding: 0 20px; /* Add some padding for smaller screens */
        }

        /* Section Titles and Descriptions */
        h2 {
            font-size: 2.0em;
            margin-bottom: 20px; /* Add some space below the title */
            text-align: center; /* Center-align titles */
            font-family: 'Times New Roman', Times, serif; /* 设置字体为 Times New Roman */
        }

        p {
            font-size: 1.5em;
            color: #333;
            margin-bottom: 20px;
            text-align: left; /* Align text to the left */
            font-family: 'Times New Roman', Times, serif; /* 设置字体为 Times New Roman */
        }

        /* Image Containers */
        .image-container {
            width: 100%; /* Ensure image container takes full width */
            text-align: center; /* Center-align images */
        }

        /* Full-width images */
        .full-width-image {
            width: 100%; /* Make images full-width */
            max-width: 100%; /* Ensure images do not overflow */
            height: auto;
            border: 1px solid #ddd;
            border-radius: 8px;
        }

        .quiz-section {
            background-color: #ffffff; /* 设置背景颜色为白色 */
            padding: 40px 100px; /* 增加上下和左右间距 */
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            gap: 20px; /* 调整左右间距 */
        }
        .quiz-section .video-column {
            flex: 3; /* 左边栏占3份 */
        }
        .quiz-section .text-column {
            flex: 2; /* 右边栏占2份 */
        }
        .quiz-section h2 {
            font-size: 2.0 em; /* 增大字体大小 */
            margin-bottom: 10px;
            font-family: 'Times New Roman', Times, serif; /* 设置字体为 Times New Roman */
        }
        .quiz-section p {
            font-size: 1em;
            color: #333;
            margin-bottom: 20px;
        }
        .quiz-section video {
            border-radius: 8px; /* 设置视频的圆角为8px */
            width: 100%; /* 视频宽度占满整个左边栏 */
            height: auto; /* 视频高度自动调整 */
        }
        .tabs {
        display: flex;
        border-bottom: 2px solid #ddd;
        padding: 0;
        margin-top: 10px;
        }
        .tab-button {
            flex: 1;
            padding: 12px 20px;
            text-align: center;
            background-color: transparent;
            border: none;
            cursor: pointer;
            transition: color 0.3s;
            font-size: 1.1em;
            font-weight: bold;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
            color: #555;
            position: relative;
        }
        .tab-button i {
            font-size: 1.2em;
        }
        .tab-button.active {
            color: #FFA500;
        }
        .tab-button.active::after {
            content: "";
            position: absolute;
            bottom: -2px;
            left: 0;
            width: 100%;
            height: 4px;
            background-color: #FFA500;
        }
        /* 设置问题字体为圆体，并调整大小 */
        /* 居中问题和选项 */
        .quiz-question p {
            font-family: 'Times New Roman', Times, serif; /* 修改字体为 Times New Roman */
            font-size: 28px; /* 加大字体 */
            font-weight: bold; /* 加粗 */
            text-align: center;
            margin-bottom: 20px;
        }

        .quiz-options {
            list-style-type: none;
            padding: 0;
            display: flex;
            flex-direction: column;
            align-items: center; /* 右对齐 */
        }

        .quiz-options li {
            margin: 10px 0;
            display: flex;
            max-width: 300px; /* 控制最大宽度 */
        }

        /* 选项按钮样式 */
        .quiz-options button {
            display: flex;
            align-items: center;
            width: auto; /* 自适应宽度 */
            padding: 15px;
            background-color: #f0f0f0;
            border: 1px solid #ccc;
            border-radius: 5px;
            cursor: pointer;
            font-size: 20px; /* 选项字体大小 */
            text-align: left;
        }

        .quiz-options button:hover {
            background-color: #ddd;
        }

        /* 选项字母标签样式 */
        .option-label {
            font-weight: bold;
            color: #333;
            margin-right: 10px;
            width: auto; /* 自适应宽度 */
            white-space: nowrap; /* 防止换行 */
        }

        /* 反馈信息样式 */
        .quiz-feedback {
            margin-top: 20px;
            font-size: 20px;
            font-weight: bold;
            text-align: center;
        }
        
        /* 新增样式规则，针对 route 和 direction 问题 */
        .quiz-feedback.hide-groundtruth span:nth-child(2) {
            display: none;
        }

        /* 背景色和字体统一 */
        .tabs-section {
            background-color: #ffffff; /* 设置与页面其他部分一致的背景色 */
            padding: 40px 0;
        }

        .tabs-section .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        .tabs-section .example-quote {
            font-size: 1.5em;
            color: #98FB98; /* 引号及其内容为绿色 */
            font-family: 'Times New Roman', Times, serif;
        }

        .tabs-section h2{
            font-size: 2.0em;
            text-align: center;
            font-family: 'Times New Roman', Times, serif;
        }

        .tabs-section p{
            font-size: 1.5em;
            color: #333;
            font-family: 'Times New Roman', Times, serif;
        }

        .task-tabs {
            display: flex;
            border-bottom: 2px solid #ddd;
            padding: 0;
            margin-top: 10px;
        }

        .task-tab-button {
            flex: 1;
            padding: 12px 20px;
            text-align: center;
            background-color: transparent;
            border: none;
            cursor: pointer;
            transition: color 0.3s;
            font-size: 1.5em; /* 统一字号 */
            font-family: 'Times New Roman', Times, serif;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
            color: #555;
            position: relative;
        }

        .task-tab-button i {
            font-size: 1.2em;
        }

        .task-tab-button.active {
            color: #FFA500;
        }

        .task-tab-button.active::after {
            content: "";
            position: absolute;
            bottom: -2px;
            left: 0;
            width: 100%;
            height: 4px;
            background-color: #FFA500;
        }

        .task-tab-content {
            display: none;
            padding: 6px 12px;
            border: 1px solid #ccc;
            border-top: none;
        }

        /* 新增图片放大样式 */
        .image-container img {
            cursor: pointer;
            transition: transform 0.3s ease-in-out;
        }

        .image-container img:hover {
            transform: scale(1.2);
        }
    </style>
</head>
<body>
    <section class="robot">
        <div class="container">
          <h1 class="title">
            <span class="highlight">ST-Bench</span> : Are MLLMs Ready for <br> Precise Spatial-Temporal World Understanding?
          </h1>
            <div class="publication-links">
                <span class="link-block">
                    <a href="https://arxiv.org/abs/your-arxiv-id" target="_blank">
                        <span class="icon"><i class="ai ai-arxiv"></i></span> arXiv
                    </a>
                </span>
                <span class="link-block">
                    <a href="assets/your-paper-name.pdf" target="_blank">
                        <span class="icon"><i class="fas fa-file-pdf"></i></span> PDF
                    </a>
                </span>
                <span class="link-block">
                    <a href="https://github.com/your-repo-name/your-dataset-folder" target="_blank">
                        <span class="icon"><i class="fas fa-database"></i></span> Dataset
                    </a>
                </span>
                <span class="link-block">
                <a href="https://github.com/IranQin/MP5" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
            </div>
        </div>
    </section>

    <!-- Logo Section -->
    <section class="logo-section">
        <div class="container">
            <div class="image-container">
                <img src="assets/images/cover.jpg"  alt="Cover" class="full-width-image">
            </div>
        </div>
    </section>

    <!-- Abstract Section -->
    <section class="abstract-section">
        <div class="container">
            <h2>Abstract</h2>
            <p>
                The use of Multimodal Large Language Models (MLLMs) as an end-to-end solution for Embodied AI and Autonomous Driving has become a prevailing trend. While MLLMs have been extensively studied for visual semantic understanding tasks, their ability to perform precise and quantitative spatial-temporal understanding in real-world applications remains largely unexamined, leading to uncertain prospects. To evaluate models' Spatial-Temporal Intelligence, we introduce ST-Bench, a benchmark designed to evaluate MLLMs' spatial-temporal understanding through challenging tasks such as estimating and predicting the appearance, pose, displacement, and motion of objects. Our benchmark encompasses a wide range of robot and vehicle operations across desktop, indoor, and outdoor scenarios. 
                The extensive experiments reveals that the state-of-the-art MLLMs still struggle in real-world spatial-temporal understanding, especially in tasks requiring precise distance estimation and motion analysis. 
            </p>
        </div>
    </section>

    <section class="demo-video-section">
        <div class="container">
            <h2>Demo Videos</h2>
            <div class="video-container">
                <video controls autoplay muted loop>
                    <source src="assets/videos/demo1.mp4" type="video/mp4">
                </video>
                <video controls autoplay muted loop>
                    <source src="assets/videos/demo2.mp4" type="video/mp4">
                </video>
                <video controls autoplay muted loop>
                    <source src="assets/videos/demo3.mp4" type="video/mp4">
                </video>
            </div>
        </div>
    </section>

    <!-- Tabs Section -->
    <section class="tabs-section">
        <div class="container">
            <h2>Tasks Definition</h2>
            <p>We have divided the questions into Static Understanding and Dynamic Understanding, and further give definitions to 8 different tasks.</p>
            <div class="task-tabs">
                <button class="task-tab-button active" onclick="openTaskTab(event, 'Static')">Static Understanding</button>
                <button class="task-tab-button" onclick="openTaskTab(event, 'Dynamic')">Dynamic Understanding</button>
            </div>

            <div id="Static" class="task-tab-content">
                <p><strong>Dimensional Measurement.</strong> Concerns estimates of an object's geometric size, such as length, width, and height, as well as the distance between objects or between the camera and an object.<br>
                    <em>Example:</em> <span class="example-quote">“What is the height of this box?”</span> or <span class="example-quote">“How close is the camera to the table?”</span>
                </p>
                <p><strong>Spatial Relation.</strong> Focuses on identifying spatial relationships among objects or between the camera and an object, including front and back, left and right, up and below.<br>
                    <em>Example:</em> <span class="example-quote">“Is the chair on the left or right side of the table?”</span> or <span class="example-quote">“What is the position of the red bag relative to the fur sofa?”</span>
                </p>
                <p><strong>3D Video Grounding.</strong> Given a semantic description such as “the red backpack on the brown sofa,” the goal is to retrieve the object's 3D bounding box in the camera coordinate system at a specific point in the video.<br>
                    <em>Example:</em> <span class="example-quote">“Locate the 3D bounding box of the red suitcase near the bed.”</span>
                </p>
            </div>

            <div id="Dynamic" class="task-tab-content" style="display: none;">
                <p><strong>Displacement and Path Length.</strong> Focuses on how far an object or the camera travels between two given time points.<br>
                    <em>Example:</em> <span class="example-quote">“How far has the car traveled from 1s to 18s?”</span>
                </p>
                <p><strong>Speed and Acceleration.</strong> Investigates motion parameters by integrating spatial displacement with time intervals.<br>
                    <em>Example:</em> <span class="example-quote">“What is the average speed of the camera?”</span> or <span class="example-quote">“How quickly is the ball accelerating?”</span>
                </p>
                <p><strong>Ego-Centric Orientation.</strong> Examines how the camera’s azimuth orientation, parallel to the ground plane, changes over the duration of the video.<br>
                    <em>Example:</em> <span class="example-quote">“How many degrees does the camera’s horizontal orientation shift from the start of the video to its end?”</span>
                </p>
                <p><strong>Trajectory Description.</strong> Describes or infers the camera’s or an object’s motion path throughout the entire video, potentially involving multiple segments of travel and turns.<br>
                    <em>Example:</em> <span class="example-quote">“Summarize the camera trajectory, including distances moved and turns made.”</span>
                </p>
                <p><strong>Pose Estimation.</strong> Given the camera’s initial 3D pose, including position and orientation, estimates its pose at a specified point in the video using only the observed RGB data.<br>
                    <em>Example:</em> <span class="example-quote">“Given the initial pose of the camera, what is the camera’s pose at the requested time?”</span>
                </p>
            </div>
        </div>
    </section>

    <!-- Comparison Section -->
    <section class="comparison-section">
        <div class="container">
            <h2>Comparison</h2>
            <div class="image-container">
                <img src="assets/images/comparison.jpg" alt="Comparison" class="full-width-image">
            </div>
            <p>
                <strong>Comparison of ST-Bench with existing benchmarks.</strong> 
                <strong>Data</strong> represents the source of our QA data, where <strong>V</strong> stands for Video and <strong>I</strong> stands for Image. 
                <strong>Env.</strong> indicates the environment in which the data is generated, where <strong>S</strong> represents Simulation and <strong>R</strong> represents Real. 
                The two columns under <strong>View</strong> indicate whether the dataset includes Ego-centric and Allocentric perspectives. 
                The two columns under <strong>Evaluation</strong> specify whether the ground truth is presented in numerical or textual form. 
                The four columns under <strong>Spatio-Temporal</strong> indicate whether the benchmark evaluates spatial distance, direction (with angular precision), velocity, or a precise and comprehensive trajectory description.
            </p>
        </div>
    </section>

    <!-- Pipeline Section -->
    <section class="pipeline-section">
        <div class="container">
            <h2>Pipeline</h2>
            <div class="image-container">
                <img src="assets/images/pipeline.jpg" alt="Pipeline" class="full-width-image">
            </div>
            <p><strong>I. Data Collection</strong> Collected data from Desktop, Indoor, and Outdoor scenarios using Omni6DPose for 6D object pose estimation, ScanNet for indoor 3D scene reconstruction, and Waymo for autonomous driving. These datasets provide frame-by-frame camera parameters and point clouds.</p>
            <p><strong>II. Automatic QA Pair Generation</strong> Generated QA pairs with MLLMs using detailed object descriptions and computed ground-truth information for each task. This process produced a diverse set of questions and challenging answer options.</p>
            <p><strong>III. Human Quality Control</strong> Conducted human quality control to filter and refine QA pairs, addressing issues like inaccurate descriptions and insufficient video information. This ensured high-quality questions and shuffled answer options for robust evaluation.</p>
            <p><strong>IV. Fine-Grained Adjustment</strong> Adjusted QA pairs with scaling factors to match the precision needs of different scenarios, from millimeters for desktop settings to meters for outdoor environments. This fine-grained adjustment helps train and evaluate MLLMs effectively.</p>
        </div>
    </section>

    <!-- Results Section -->
    <section class="results-section">
        <div class="container">
            <h2>Results</h2>
            <div class="image-container">
                <img src="assets/images/results.jpg" alt="Results" class="full-width-image">
                <img src="assets/images/radar.jpg" alt="Radar" class="full-width-image">
            </div>
            <p>Here is the results information.</p>
        </div>
    </section>

    <section class="quiz-section">
      <div class="video-column">
          <h2>QUIZ</h2>
          <video id="quiz-video" controls autoplay muted loop>
              <source src="assets/videos/demo1.mp4" type="video/mp4">
          </video>
      </div>
      <div class="text-column">
          <div class="tabs">
              <button class="tab-button active" onclick="showTab(0)"><i class="fas fa-rocket"></i> Velocity </button>
              <button class="tab-button" onclick="showTab(1)"><i class="fas fa-ruler"></i> Distance </button>
              <button class="tab-button" onclick="showTab(2)"><i class="fa-solid fa-route"></i> Route </button>
              <button class="tab-button" onclick="showTab(3)"><i class="fa-regular fa-compass"></i> Direction </button>
          </div>
          <div class="tab-content" id="tab-content">
              <!-- 默认显示第一个 Tab 的内容 -->
              <div class="quiz-question">
                  <p>What is the velocity of the object?</p>
                  <ul class="quiz-options">
                      <li><button onclick="checkAnswer(0, 0)">10 m/s</button></li>
                      <li><button onclick="checkAnswer(0, 1)">20 m/s</button></li>
                      <li><button onclick="checkAnswer(0, 2)">30 m/s</button></li>
                  </ul>
                  <p id="quiz-feedback-0" class="quiz-feedback"></p>
              </div>
          </div>
      </div>
    </section>
  
    <section class="conclusion-section">
        <div class="container">
            <h2>Conclusion</h2>
            <p>
                We introduced ST-Bench, a comprehensive benchmark to assess MLLMs’ spatial-temporal understanding through over 300 real-world videos and 2,000 QA pairs of robot desktop, indoor, and outdoor scenarios. Experiments show that, while state-of-the-art MLLMs handle basic pose estimation and object grounding competently, they often struggle with more fine-grained tasks such as precise distance and velocity estimation, displacement tracking, and ego-centric orientation. These shortcomings appear to stem from issues like sparse temporal sampling in pretraining, insufficient 3D annotations, and a lack of dedicated physical reasoning modules. By highlighting these gaps, ST-Bench provides a valuable platform for guiding future research on strengthening spatial-temporal understanding in MLLMs — an essential step toward improving their applicability in complex real-world applications.
            </p>
        </div>
    </section>

    <script>
        function openTaskTab(evt, tabName) {
            // 获取所有标签内容并隐藏
            var i, tabcontent, tablinks;
            tabcontent = document.getElementsByClassName("task-tab-content");
            for (i = 0; i < tabcontent.length; i++) {
                tabcontent[i].style.display = "none";
            }
            tablinks = document.getElementsByClassName("task-tab-button");
            for (i = 0; i < tablinks.length; i++) {
                tablinks[i].className = tablinks[i].className.replace(" active", "");
            }
            // 显示当前标签内容
            document.getElementById(tabName).style.display = "block";
            evt.currentTarget.className += " active";
        }
    
        // 默认打开第一个标签
        document.querySelector(".task-tab-button.active").click();
    </script>

  <script>
    // 定义问题和答案
    const questions = [
        {
            question: "What is the velocity of the object when t=0s ?",
            options: ["10 m/s", "20 m/s", "30 m/s", "40 m/s"],
            correctAnswer: 1, // 正确答案的索引
            GroundTruth: "The GroundTruth is 19.2m/s."
        },
        {
            question: "What is the distance traveled from t=0s to t=1s?",
            options: ["50 m", "100 m", "150 m", "200 m"],
            correctAnswer: 2,
            GroundTruth: "The GroundTruth is 152m."
        },
        {
            question: "What is the route taken?",
            options: ["Route A", "Route B", "Route C","Route D"],
            correctAnswer: 0,
            GroundTruth: "The correct answer is Route A.",
            isRouteOrDirection: true // 添加标识符
        },
        {
            question: "What is the direction of movement?",
            options: ["North", "South", "East ","West "],
            correctAnswer: 2,
            GroundTruth: "The correct answer is East.",
            isRouteOrDirection: true // 添加标识符
        }
    ];

    // 显示 Tab 内容
    function showTab(index) {
        const question = questions[index];
        const optionsHTML = question.options.map((option, i) => `
            <li>
                <button onclick="checkAnswer(${index}, ${i})">
                    <span class="option-label">${String.fromCharCode(65 + i)}</span>
                    <span class="option-text">${option}</span>
                </button>
            </li>
        `).join("");

        document.getElementById("tab-content").innerHTML = `
            <div class="quiz-question">
                <p>${question.question}</p>
                <ul class="quiz-options">${optionsHTML}</ul>
                <p id="quiz-feedback-${index}" class="quiz-feedback"></p>
            </div>
        `;

        // 更新 Tab 按钮的激活状态
        document.querySelectorAll(".tab-button").forEach((btn, i) => {
            btn.classList.toggle("active", i === index);
        });
    }

    // 检查答案
    function checkAnswer(questionIndex, selectedIndex) {
        const question = questions[questionIndex];
        const feedbackElement = document.getElementById(`quiz-feedback-${questionIndex}`);

        let feedbackContent = "";
        if (selectedIndex === question.correctAnswer) {
            feedbackContent = "<span style='color: green;'> Correct! 🎉</span>";
            // 如果是 route 或 direction 的问题，隐藏 GroundTruth
            if (question.isRouteOrDirection) {
                feedbackElement.classList.add("hide-groundtruth");
            } else {
                feedbackElement.classList.remove("hide-groundtruth");
                feedbackContent += `<br><span>${question.GroundTruth}</span>`;
            }
        } else {
            feedbackElement.classList.remove("hide-groundtruth");
            feedbackContent = `
                <span style='color: red;'> Incorrect!</span><br>
                <span>${question.GroundTruth}</span>
            `;
        }

        feedbackElement.innerHTML = feedbackContent;
    }

    // 定义时间点
    const t1 = 0; // 替换为实际时间（秒）
    const t2 = 5;
    const t3 = 10;
    const t4 = 15;

    // 获取视频元素
    const video = document.getElementById("quiz-video");

    // 获取所有 Tab 按钮
    const tabButtons = document.querySelectorAll(".tab-button");

    // 为每个 Tab 按钮添加点击事件监听器
    tabButtons.forEach((button, index) => {
        button.addEventListener("click", () => {
            // 根据点击的 Tab 跳转到对应的时间点
            switch (index) {
                case 0:
                    video.currentTime = t1;
                    break;
                case 1:
                    video.currentTime = t2;
                    break;
                case 2:
                    video.currentTime = t3;
                    break;
                case 3:
                    video.currentTime = t4;
                    break;
            }
            // 显示对应的 Tab 内容
            showTab(index);
        });
    });

    // 初始化显示第一个 Tab 的内容
    showTab(0);
</script>
  
</body>
</html>